
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 26: scikit-learn &#8212; Computational Problem Solving in the Chemical Sciences</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css?v=564be945" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture-28-scikit-learn';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 27: Nested Sampling" href="lecture-29-nested-sampling.html" />
    <link rel="prev" title="Chapter 25: Kinetic Monte Carlo" href="lecture-27-kinetic-mc.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Computational Problem Solving in the Chemical Sciences - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Computational Problem Solving in the Chemical Sciences - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to Computational Problem Solving in the Chemical Sciences
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 1. Introduction to Python Computations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-01-introduction.html">Chapter 1: Introduction to Python for the Chemical Sciences</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-02-packages.html">Chapter 2: Essential Python Packages for the Chemical Sciences</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-03-control.html">Chapter 3: Control Structures in Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 2. Numerical Methods in Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-04-optimization.html">Chapter 4: Chemical Reaction Equilibria and Roots of Equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-05-integration.html">Chapter 5: Chemical Bonding and Numerical Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-06-linalg.html">Chapter 6: Balancing Chemical Equations and Systems of Linear Algebraic Equations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 3. Statistics — Regression and Correlation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-07-regression.html">Chapter 7: Orders of Reaction and Linear Regression Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-08-calibration.html">Chapter 8: Calibration Data, Confidence Intervals, and Correlation Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 4. Introduction to Molecular Simulations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-09-thermo.html">Chapter 9: Classical Thermodynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-10-stat-thermo.html">Chapter 10: Statistical Thermodynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-11-ensembles.html">Chapter 11: Ensembles and Ergodicity</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 5. Monte Carlo Simulations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-12-monte-carlo.html">Chapter 12: The Monte Carlo Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-13-mc-integration.html">Chapter 13: Monte Carlo Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-14-metropolis.html">Chapter 14: A Basic Monte Carlo Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-15-nanoparticles.html">Chapter 15: Nanoparticle Shape and Simulated Annealing</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-16-tech-details.html">Chapter 16: Technical Details: Boundary Conditions, Truncation of Interactions, <em>Etc.</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-17-lipids.html">Chapter 17: Lipid Interactions in Membranes and Monte Carlo Simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-18-adsorption.html">Chapter 18: Monte Carlo Simulations of Adsorption on Surfaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-19-project-1.html">Project 1: Grand Canonical Monte Carlo Simulations of Competitive Adsorption</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 6. Molecular Dynamics Simulations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-20-molecular-dynamics.html">Chapter 19: Molecular Dynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-21-verlet.html">Chapter 20: Verlet Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-22-thermostatting.html">Chapter 21: Thermostatting</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-23-ase.html">Chapter 22: Atomic Simulation Environment (ASE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-24-radial-dist.html">Chapter 23: Radial Distribution Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-25-project-2.html">Project 2: Molecular Dynamics Simulations of a Polymer Chain</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 7. Advanced and Emerging Topics in Computational Chemistry</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lecture-26-newton-raphson.html">Chapter 24: Newton-Raphson Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-27-kinetic-mc.html">Chapter 25: Kinetic Monte Carlo</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 26: <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture-29-nested-sampling.html">Chapter 27: Nested Sampling</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Flecture-28-scikit-learn.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/lecture-28-scikit-learn.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 26: scikit-learn</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scikit-learn"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#installation">Installation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">Supervised Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-by-example-wine-classification">Machine Learning by Example: Wine Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-get-the-data">Step 1: Get the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-explore-and-visualize-the-data">Step 2: Explore and Visualize the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-preprocess-the-data">Step 3: Preprocess the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-train-a-model">Step 4: Train a Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-evaluate-the-model">Step 5: Evaluate the Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-plot-and-interpret-the-coefficients">Step 6: Plot and Interpret the Coefficients</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regression">Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-by-example-oxygen-vacancy-formation-energy-prediction">Machine Learning by Example: Oxygen Vacancy Formation Energy Prediction</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-use-pip-or-conda-to-install-openpyxl">Step 1: Use <code class="docutils literal notranslate"><span class="pre">pip</span></code> or <code class="docutils literal notranslate"><span class="pre">conda</span></code> to Install <code class="docutils literal notranslate"><span class="pre">openpyxl</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-get-the-data">Step 2: Get the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-explore-and-visualize-the-data">Step 3: Explore and Visualize the Data</a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#missing-values">Missing Values</a></li>
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration">Data Exploration</a></li>
</ul>
</li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-preprocess-the-data">Step 4: Preprocess the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-train-a-model">Step 5: Train a Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-evaluate-the-model">Step 6: Evaluate the Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-7-plot-and-interpret-the-coefficients">Step 7: Plot and Interpret the Coefficients</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-26-scikit-learn">
<h1>Chapter 26: <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code><a class="headerlink" href="#chapter-26-scikit-learn" title="Link to this heading">#</a></h1>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<p>By the end of this lecture, you will be able to:</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> to perform supervised learning</p></li>
<li><p>Understand the difference between classification and regression</p></li>
<li><p>Train and evaluate classification models</p></li>
<li><p>Train and evaluate regression models</p></li>
</ul>
</section>
<section id="scikit-learn">
<h2><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code><a class="headerlink" href="#scikit-learn" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> is a Python package that provides simple and efficient tools for data analysis. It is built on <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, <code class="docutils literal notranslate"><span class="pre">scipy</span></code>, and <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>. It is open source and commercially usable under the BSD license. It is a great tool for machine learning in Python.</p>
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Link to this heading">#</a></h3>
<p>To install <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, you can follow the instructions on the <a class="reference external" href="https://scikit-learn.org/stable/install.html">official website</a>. You can install it using <code class="docutils literal notranslate"><span class="pre">pip</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>scikit-learn
</pre></div>
</div>
</section>
</section>
<section id="supervised-learning">
<h2>Supervised Learning<a class="headerlink" href="#supervised-learning" title="Link to this heading">#</a></h2>
<p>In supervised learning, we have a dataset consisting of both input features and output labels. The goal is to learn a mapping from the input to the output. We have two types of supervised learning:</p>
<ol class="arabic simple">
<li><p>Classification: The output is a category.</p></li>
<li><p>Regression: The output is a continuous value.</p></li>
</ol>
<section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Link to this heading">#</a></h3>
<p>In classification, we have a dataset consisting of input features and output labels. The goal is to learn a mapping from the input features to the output labels. We can use the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> library to perform classification.</p>
<section id="machine-learning-by-example-wine-classification">
<h4>Machine Learning by Example: Wine Classification<a class="headerlink" href="#machine-learning-by-example-wine-classification" title="Link to this heading">#</a></h4>
<p>Let’s consider an example of wine classification. We have a dataset of wines with different features such as alcohol content, acidity, etc. We want to classify the wines into different categories based on these features.</p>
<section id="step-1-get-the-data">
<h5>Step 1: Get the Data<a class="headerlink" href="#step-1-get-the-data" title="Link to this heading">#</a></h5>
<p>First, we need to load the dataset. We can use the <code class="docutils literal notranslate"><span class="pre">load_wine</span></code> function from <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code> to load the wine dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_wine</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_wine</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;numpy&#39;
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Wine Recognition Dataset</p>
<p>The wine recognition dataset is a classic dataset for classification. It contains 178 samples of wine with 13 features each. The features are the chemical composition of the wines, and the target is the class of the wine (0, 1, or 2). You can find more information about the dataset <a class="reference external" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset">here</a>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Your Data</p>
<p>If <code class="docutils literal notranslate"><span class="pre">pandas</span></code> can read your data, you can swap out the <code class="docutils literal notranslate"><span class="pre">load_wine</span></code> function with <code class="docutils literal notranslate"><span class="pre">pd.read_csv</span></code> or any other method you prefer to load your data.</p>
</div>
</section>
<section id="step-2-explore-and-visualize-the-data">
<h5>Step 2: Explore and Visualize the Data<a class="headerlink" href="#step-2-explore-and-visualize-the-data" title="Link to this heading">#</a></h5>
<p>Next, we need to explore and visualize the data to understand its structure and characteristics. We can use <code class="docutils literal notranslate"><span class="pre">pandas</span></code> to explore the data and <code class="docutils literal notranslate"><span class="pre">seaborn</span></code> to visualize it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-3-preprocess-the-data">
<h5>Step 3: Preprocess the Data<a class="headerlink" href="#step-3-preprocess-the-data" title="Link to this heading">#</a></h5>
<p>Before training the model, we need to preprocess the data. This involves splitting the data into input features and output labels, normalizing the input features, and splitting the data into training and testing sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Why Split the Data?</p>
<p>Splitting the data into training and testing sets allows us to train the model on one set and evaluate it on another set. This helps us assess the model’s performance on unseen data. You can also use <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html">cross-validation</a> to evaluate the model’s performance more robustly.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Why Scale or “Standardize” the Data?</p>
<p>Standardizing the data (<em>e.g.</em>, using <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>) ensures that each feature has a mean of 0 and a standard deviation of 1. This can help improve the performance of some machine learning algorithms, especially those that are sensitive to the scale of the input features.</p>
</div>
</section>
<section id="step-4-train-a-model">
<h5>Step 4: Train a Model<a class="headerlink" href="#step-4-train-a-model" title="Link to this heading">#</a></h5>
<p>Now that we have preprocessed the data, we can train a classification model. We will use the <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> models from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p>
<div class="tip admonition">
<p class="admonition-title">Logistic Regression</p>
<p>Logistic regression is a linear model used for binary classification. It models the probability of the output being in a particular category. You can find more information about logistic regression <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">here</a>.</p>
<p><img alt="Alt text" src="https://upload.wikimedia.org/wikipedia/commons/c/cb/Exam_pass_logistic_curve.svg" /></p>
<p>Canley, CC BY-SA 4.0 <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0">https://creativecommons.org/licenses/by-sa/4.0</a>, via Wikimedia Commons</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Random Forest</p>
<p>Random forests are an ensemble learning method that builds multiple decision trees during training and outputs the mode of the classes (<em>i.e.</em>, the most frequent class) as the prediction. You can find more information about random forests <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees">here</a>.</p>
<p><img alt="Alt text" src="https://media.datacamp.com/legacy/v1718113325/image_7f309c633f.png" /></p>
<p><a class="reference external" href="https://www.datacamp.com/tutorial/random-forests-classifier-python">DataCamp</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Train the Logistic Regression model</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_lr</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Train the Random Forest model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Plot the confusion matrix</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">)</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Confusion Matrix</p>
<p>A confusion matrix is a table that is often used to describe the performance of a classification model. It shows the number of true positives, true negatives, false positives, and false negatives. You can find more information about confusion matrices <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix">here</a>.</p>
</div>
</section>
<section id="step-5-evaluate-the-model">
<h5>Step 5: Evaluate the Model<a class="headerlink" href="#step-5-evaluate-the-model" title="Link to this heading">#</a></h5>
<p>Finally, we need to evaluate the model’s performance. We can use metrics such as accuracy, precision, recall, and F1 score to evaluate the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Random Forest:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Classification Report</p>
<p>A classification report shows the precision, recall, F1 score, and support for each class in the classification model. Precision is the ratio of true positives to the sum of true positives and false positives</p>
<div class="math notranslate nohighlight">
\[
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
\]</div>
<p>Recall is the ratio of true positives to the sum of true positives and false negatives</p>
<div class="math notranslate nohighlight">
\[
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
\]</div>
<p>The F1 score is the harmonic mean of precision and recall</p>
<div class="math notranslate nohighlight">
\[
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\]</div>
<p>Support is the number of occurrences of each class in the dataset.</p>
</div>
</section>
<section id="step-6-plot-and-interpret-the-coefficients">
<h5>Step 6: Plot and Interpret the Coefficients<a class="headerlink" href="#step-6-plot-and-interpret-the-coefficients" title="Link to this heading">#</a></h5>
<p>For the logistic regression model, we can plot and interpret the coefficients to understand the importance of each feature in the classification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Ensure feature names are a NumPy array</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Sort the coefficients</span>
<span class="n">sorted_idx</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>

<span class="c1"># Plot the coefficients</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">feature_names</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">],</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">sorted_idx</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Coefficient Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature Name&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Logistic Regression Coefficients&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The plot above shows the coefficients of the logistic regression model. The features with the largest coefficients (in absolute value) are the most important for the classification. The sign of the coefficient indicates the direction of the relationship between the feature and the target. The two features with the largest coefficients are <code class="docutils literal notranslate"><span class="pre">proline</span></code> and <code class="docutils literal notranslate"><span class="pre">alcalinity_of_ash</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">proline</span></code> is the amount of proline in the wine. Proline is an amino acid that is found in high concentrations in red wines. The coefficient for <code class="docutils literal notranslate"><span class="pre">proline</span></code> is positive, indicating that wines with higher proline content are more likely to be classified as class 2.</p>
<figure class="align-default" id="proline">
<a class="reference internal image-reference" href="https://upload.wikimedia.org/wikipedia/commons/4/45/L-Proline.svg"><img alt="https://upload.wikimedia.org/wikipedia/commons/4/45/L-Proline.svg" src="https://upload.wikimedia.org/wikipedia/commons/4/45/L-Proline.svg" style="width: 200px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">The chemical structure of proline. By Qohelet12, CC0, via Wikimedia Commons</span><a class="headerlink" href="#proline" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><code class="docutils literal notranslate"><span class="pre">alcalinity_of_ash</span></code> is the amount of ash in the wine. Ash is the inorganic residue remaining after the water and organic matter have been removed by heating. The coefficient for <code class="docutils literal notranslate"><span class="pre">alcalinity_of_ash</span></code> is negative, indicating that wines with lower ash content are more likely to be classified as class 2.</p>
<div class="tip admonition">
<p class="admonition-title">Your Data</p>
<p>You can swap out the wine dataset with your own dataset to perform classification on your data. Make sure to preprocess the data, train the model, and evaluate the model as shown in the example above.</p>
</div>
</section>
</section>
</section>
<section id="regression">
<h3>Regression<a class="headerlink" href="#regression" title="Link to this heading">#</a></h3>
<p>In regression, we have a dataset consisting of input features and continuous output values. The goal is to learn a mapping from the input features to the output values. We can use the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> library to perform regression.</p>
<section id="machine-learning-by-example-oxygen-vacancy-formation-energy-prediction">
<h4>Machine Learning by Example: Oxygen Vacancy Formation Energy Prediction<a class="headerlink" href="#machine-learning-by-example-oxygen-vacancy-formation-energy-prediction" title="Link to this heading">#</a></h4>
<p>Let’s consider an example of regression for predicting the oxygen vacancy formation energy in materials. We have an <a class="reference external" href="https://wustl.instructure.com/files/8915454/download?download_frd=1">Excel file</a> containing the features of the materials and the oxygen vacancy formation energy. We want to train a regression model to predict the oxygen vacancy formation energy based on the features of the materials.</p>
<section id="step-1-use-pip-or-conda-to-install-openpyxl">
<h5>Step 1: Use <code class="docutils literal notranslate"><span class="pre">pip</span></code> or <code class="docutils literal notranslate"><span class="pre">conda</span></code> to Install <code class="docutils literal notranslate"><span class="pre">openpyxl</span></code><a class="headerlink" href="#step-1-use-pip-or-conda-to-install-openpyxl" title="Link to this heading">#</a></h5>
<p>Before we can read the Excel file, we need to install the <code class="docutils literal notranslate"><span class="pre">openpyxl</span></code> library. You can install it using <code class="docutils literal notranslate"><span class="pre">pip</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>openpyxl
</pre></div>
</div>
</section>
<section id="step-2-get-the-data">
<h5>Step 2: Get the Data<a class="headerlink" href="#step-2-get-the-data" title="Link to this heading">#</a></h5>
<p>First, we need to load the dataset. We can use the <code class="docutils literal notranslate"><span class="pre">pd.read_excel</span></code> function from <code class="docutils literal notranslate"><span class="pre">pandas</span></code> to load the Excel file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;ovfe-deml.xlsx&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Oxygen Vacancy Formation Energy Dataset</p>
<p>The oxygen vacancy formation energy dataset contains the features of materials and the oxygen vacancy formation energy. The features include the crystal structure (<code class="docutils literal notranslate"><span class="pre">xtal_str</span></code>), the composition (<code class="docutils literal notranslate"><span class="pre">comp</span></code>), the standard enthalpy of formation (<code class="docutils literal notranslate"><span class="pre">dHf</span></code>), the measured and calculated band gaps (<code class="docutils literal notranslate"><span class="pre">Eg_exp</span></code>, <code class="docutils literal notranslate"><span class="pre">Eg_GW</span></code>, and <code class="docutils literal notranslate"><span class="pre">Eg_DFTU</span></code>), the valence band maximum (<code class="docutils literal notranslate"><span class="pre">O2p_min_VBM</span></code>), the difference between the electronegativity of the cation and anion (<code class="docutils literal notranslate"><span class="pre">dEN</span></code>), and the energy above the convex hull (<code class="docutils literal notranslate"><span class="pre">Ehull_MP</span></code>). The energy above the convex hull is a measure of the thermodynamic stability of the material. The higher the energy above the convex hull, the less stable the material. The target is the oxygen vacancy formation energy (<code class="docutils literal notranslate"><span class="pre">OVFE_calc</span></code>). You can find more information about the dataset <a class="reference external" href="https://doi.org/10.1021/acs.jpclett.5b00710">here</a>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Your Data</p>
<p>If <code class="docutils literal notranslate"><span class="pre">pandas</span></code> can read your data, you can swap out the <code class="docutils literal notranslate"><span class="pre">pd.read_excel</span></code> function with <code class="docutils literal notranslate"><span class="pre">pd.read_csv</span></code> or any other method you prefer to load your data.</p>
</div>
</section>
<section id="step-3-explore-and-visualize-the-data">
<h5>Step 3: Explore and Visualize the Data<a class="headerlink" href="#step-3-explore-and-visualize-the-data" title="Link to this heading">#</a></h5>
<p>Next, we need to explore and visualize the data to understand its structure and characteristics. We can use <code class="docutils literal notranslate"><span class="pre">pandas</span></code> to explore the data and <code class="docutils literal notranslate"><span class="pre">seaborn</span></code> to visualize it.</p>
<section id="missing-values">
<h6>Missing Values<a class="headerlink" href="#missing-values" title="Link to this heading">#</a></h6>
<p>Before exploring the data, we need to check for missing values and handle them if necessary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The measured band gap (<code class="docutils literal notranslate"><span class="pre">Eg_exp</span></code>) and the energy above the convex hull (<code class="docutils literal notranslate"><span class="pre">Ehull_MP</span></code>) have nine and two missing values, respectively. We can drop these columns or impute the missing values with the mean, median, or mode of the column. Let’s drop the columns for now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Eg_exp&#39;</span><span class="p">,</span> <span class="s1">&#39;Ehull_MP&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Missing Values</p>
<p>Missing values can affect the performance of machine learning models. It is important to handle missing values appropriately by imputing them or dropping the corresponding rows or columns. You can find more information about handling missing values <a class="reference external" href="https://scikit-learn.org/stable/modules/impute.html">here</a>.</p>
</div>
</section>
<section id="data-exploration">
<h6>Data Exploration<a class="headerlink" href="#data-exploration" title="Link to this heading">#</a></h6>
<p>Now, let’s explore the data to understand its structure and characteristics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;reg&#39;</span><span class="p">,</span> <span class="n">diag_kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-4-preprocess-the-data">
<h5>Step 4: Preprocess the Data<a class="headerlink" href="#step-4-preprocess-the-data" title="Link to this heading">#</a></h5>
<p>Before training the model, we need to preprocess the data. This involves splitting the data into input features and output labels, normalizing the input features, and splitting the data into training and testing sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;xtal_str&#39;</span><span class="p">,</span> <span class="s1">&#39;comp&#39;</span><span class="p">,</span> <span class="s1">&#39;OVFE_calc&#39;</span><span class="p">,</span> <span class="s1">&#39;OVFE_reg_GW&#39;</span><span class="p">,</span> <span class="s1">&#39;OVFE_reg_DFTU&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OVFE_calc&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-5-train-a-model">
<h5>Step 5: Train a Model<a class="headerlink" href="#step-5-train-a-model" title="Link to this heading">#</a></h5>
<p>Now that we have preprocessed the data, we can train a regression model. We will use the <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> and <code class="docutils literal notranslate"><span class="pre">Perceptron</span></code> models from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p>
<div class="tip admonition">
<p class="admonition-title">Ridge regression</p>
<p>Ridge regression is a linear model used for regression. It is similar to ordinary least squares regression, but it adds a penalty term to the loss function to prevent overfitting by shrinking the coefficients. You can find more information about ridge regression <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression">here</a>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Multi-layer Perceptron (MLP)</p>
<p>The multi-layer perceptron (MLP) is a type of artificial neural network that consists of multiple layers of nodes. It is a powerful model that can learn complex patterns in the data. You can find more information about MLPs <a class="reference external" href="https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron">here</a>.</p>
<figure class="align-default" id="mlp">
<a class="reference internal image-reference" href="https://scikit-learn.org/stable/_images/multilayerperceptron_network.png"><img alt="https://scikit-learn.org/stable/_images/multilayerperceptron_network.png" src="https://scikit-learn.org/stable/_images/multilayerperceptron_network.png" style="width: 400px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">A multi-layer perceptron (MLP) neural network. <a class="reference external" href="https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron">Source</a></span><a class="headerlink" href="#mlp" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">RidgeCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>

<span class="c1"># Train the Ridge regression model</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">()</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_ridge</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Train the MLPRegressor model</span>
<span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
    <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_mlp</span> <span class="o">=</span> <span class="n">mlp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Plot the predicted vs. actual values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ridge&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_mlp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MLP&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)],</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Actual Oxygen Vacancy Formation Energy (eV)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Oxygen Vacancy Formation Energy (eV)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-6-evaluate-the-model">
<h5>Step 6: Evaluate the Model<a class="headerlink" href="#step-6-evaluate-the-model" title="Link to this heading">#</a></h5>
<p>Finally, we need to evaluate the model’s performance. We can use metrics such as mean squared error (MSE), mean absolute error (MAE), and <span class="math notranslate nohighlight">\(R^2\)</span> score to evaluate the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Ridge Regression:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MSE:&#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MAE:&#39;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R^2:&#39;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_ridge</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MLPRegressor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MSE:&#39;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_mlp</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MAE:&#39;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_mlp</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R^2:&#39;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_mlp</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Regression Metrics</p>
<p>Mean squared error (MSE) is the average of the squared differences between the predicted and actual values</p>
<div class="math notranslate nohighlight">
\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</div>
<p>Mean absolute error (MAE) is the average of the absolute differences between the predicted and actual values</p>
<div class="math notranslate nohighlight">
\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]</div>
<p>The <span class="math notranslate nohighlight">\(R^2\)</span> score is the coefficient of determination and represents the proportion of the variance in the dependent variable that is predictable from the independent variables</p>
<div class="math notranslate nohighlight">
\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Your Data</p>
<p>You can swap out the oxygen vacancy formation energy dataset with your own dataset to perform regression on your data. Make sure to preprocess the data, train the model, and evaluate the model as shown in the example above.</p>
</div>
</section>
<section id="step-7-plot-and-interpret-the-coefficients">
<h5>Step 7: Plot and Interpret the Coefficients<a class="headerlink" href="#step-7-plot-and-interpret-the-coefficients" title="Link to this heading">#</a></h5>
<p>For the Ridge regression model, we can plot and interpret the coefficients to understand the importance of each feature in the regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ensure feature names are a NumPy array</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Sort the coefficients</span>
<span class="n">sorted_idx</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>

<span class="c1"># Plot the coefficients</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">feature_names</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">],</span> <span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Coefficient Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature Name&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Ridge Regression Coefficients&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The plot above shows the coefficients of the Ridge regression model. The features with the largest coefficients (in absolute value) are the most important for the regression. The sign of the coefficient indicates the direction of the relationship between the feature and the target. The feature with the largest coefficient is <code class="docutils literal notranslate"><span class="pre">dHf</span></code>.</p>
<div class="tip admonition">
<p class="admonition-title">Interpretation</p>
<p><code class="docutils literal notranslate"><span class="pre">dHf</span></code> is the standard enthalpy of formation of the material. The formation reaction of a metal oxide (MO<span class="math notranslate nohighlight">\(_x\)</span>) can be represented as</p>
<div class="math notranslate nohighlight">
\[
\text{M} + \frac{x}{2} \text{O}_2 \rightarrow \text{MO}_x
\]</div>
<p>This reaction can be thought of as an oxidation reaction, where the metal is oxidized to form the metal oxide, and its standard enthalpy change can be thought of as an enthalpy of oxidation. Since oxygen vacancy formation is a reduction reaction, the oxygen vacancy formation energy is inversely related to the standard enthalpy of formation. The coefficient for <code class="docutils literal notranslate"><span class="pre">dHf</span></code> is negative, indicating that materials with lower standard enthalpies of formation have higher oxygen vacancy formation energies.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Materials Design</p>
<p>This relationship is exciting because it suggests that we can predict the oxygen vacancy formation energy of metal oxides, which is challenging to measure experimentally, based on their standard enthalpies of formation, which are readily available from databases like the <a class="reference external" href="https://next-gen.materialsproject.org/">Materials Project</a>, <a class="reference external" href="http://aflow.org/">AFLOW</a>, and <a class="reference external" href="http://oqmd.org/">OQMD</a>. This prediction can help guide the design of materials with desired properties for applications like solid oxide fuel cells, oxygen separation membranes, catalysts, and <a class="reference external" href="https://wexlergroup.github.io/research/#solar-thermochemical-hydrogen-production">thermochemical water and carbon dioxide splitting</a>.</p>
</div>
</section>
</section>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h3>
<p>In this lecture, we learned how to use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> to perform supervised learning. We covered classification and regression and trained models on the wine recognition dataset and the oxygen vacancy formation energy dataset. We explored the data, preprocessed it, trained the models, evaluated the models, and interpreted the results. We used logistic regression and random forests for classification and ridge regression and MLPRegressor for regression. We also visualized the data, plotted the confusion matrix, and interpreted the coefficients.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture-27-kinetic-mc.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 25: Kinetic Monte Carlo</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture-29-nested-sampling.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 27: Nested Sampling</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scikit-learn"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#installation">Installation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">Supervised Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-by-example-wine-classification">Machine Learning by Example: Wine Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-get-the-data">Step 1: Get the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-explore-and-visualize-the-data">Step 2: Explore and Visualize the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-preprocess-the-data">Step 3: Preprocess the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-train-a-model">Step 4: Train a Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-evaluate-the-model">Step 5: Evaluate the Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-plot-and-interpret-the-coefficients">Step 6: Plot and Interpret the Coefficients</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regression">Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-by-example-oxygen-vacancy-formation-energy-prediction">Machine Learning by Example: Oxygen Vacancy Formation Energy Prediction</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-use-pip-or-conda-to-install-openpyxl">Step 1: Use <code class="docutils literal notranslate"><span class="pre">pip</span></code> or <code class="docutils literal notranslate"><span class="pre">conda</span></code> to Install <code class="docutils literal notranslate"><span class="pre">openpyxl</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-get-the-data">Step 2: Get the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-explore-and-visualize-the-data">Step 3: Explore and Visualize the Data</a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#missing-values">Missing Values</a></li>
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration">Data Exploration</a></li>
</ul>
</li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-preprocess-the-data">Step 4: Preprocess the Data</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-train-a-model">Step 5: Train a Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-evaluate-the-model">Step 6: Evaluate the Model</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-7-plot-and-interpret-the-coefficients">Step 7: Plot and Interpret the Coefficients</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert B. Wexler
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>