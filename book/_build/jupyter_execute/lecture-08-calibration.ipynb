{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c21725f",
   "metadata": {},
   "source": [
    "# Chapter 8: Calibration Data, Confidence Intervals, and Correlation Analysis\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lecture, you should be able to\n",
    "\n",
    "1. **Develop and interpret calibration curves** using ordinary least squares (OLS) regression for experimental data.\n",
    "2. **Calculate and interpret confidence intervals** for the slope and intercept of linear models to assess the precision of estimates.\n",
    "3. **Perform correlation analysis** to evaluate the strength and direction of relationships between variables in calibration data.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Calibration data is a set of data used to establish a relationship between two variables. In calibration, this relationship is typically linear and is used to predict one variable's value based on the other variable's value. In this lecture, we will discuss how to analyze calibration data, including calculating confidence intervals for the slope and intercept of the calibration curve and performing correlation analysis to assess the strength of the relationship between the two variables.\n",
    "\n",
    "## Calibration Data\n",
    "\n",
    "Imagine you are an analytical chemist working for a major brewing company. You have been tasked with developing a new method for measuring the diacetyl concentration in beer. *Diacetyl* is a compound produced during fermentation responsible for a beer's buttery flavor. The company wants to ensure that the diacetyl concentration in its beer is below a certain threshold to maintain the desired flavor profile.\n",
    "\n",
    "After doing some research, you recommend to your company that an ultraviolet-visible (UV-Vis) spectrometer be used to measure the diacetyl concentration. You have found that diacetyl has a strong absorbance peak at 530 nm. You have also found that the absorbance of diacetyl is linearly related to its concentration (*i.e.*, follows Beer's Law). You have also found that the absorbance of diacetyl is not affected by the presence of other compounds in beer.\n",
    "\n",
    "You have collected the following data.\n",
    "\n",
    "| Sample concentration (mg/L) | Absorbance value (530 nm) |\n",
    "|-----------------------------|---------------------------|\n",
    "| 0.5                         | 0.004                     |\n",
    "| 1.0                         | 0.007                     |\n",
    "| 1.5                         | 0.013                     |\n",
    "| 3.0                         | 0.026                     |\n",
    "| 4.0                         | 0.032                     |\n",
    "\n",
    "You want to use this data to develop a calibration curve that can predict the diacetyl concentration in beer based on the absorbance value measured by the UV-Vis spectrometer.\n",
    "\n",
    "## Calibration Curve\n",
    "\n",
    "The first step in analyzing calibration data is plotting it and fitting a line. This line is called the calibration curve and represents the relationship between the two variables. In this case, the calibration curve represents the relationship between the diacetyl concentration and the absorbance value.\n",
    "\n",
    "Let us plot the data and fit a line to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eeb39b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mols_slope\u001b[39m(x, y):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ols_slope(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
    "    denominator = np.sum((x - x_mean) ** 2)\n",
    "    return numerator / denominator\n",
    "\n",
    "def ols_intercept(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    slope = ols_slope(x, y)\n",
    "    return y_mean - slope * x_mean\n",
    "\n",
    "def ols(x, y):\n",
    "    slope = ols_slope(x, y)\n",
    "    intercept = ols_intercept(x, y)\n",
    "    return slope, intercept\n",
    "\n",
    "# Data\n",
    "concentration = np.array([0.5, 1.0, 1.5, 3.0, 4.0])\n",
    "absorbance = np.array([0.004, 0.007, 0.013, 0.026, 0.032])\n",
    "\n",
    "# Fit a line to the data\n",
    "slope, intercept = ols(concentration, absorbance)\n",
    "line = slope * concentration + intercept\n",
    "\n",
    "# Plot the calibration curve with the residuals\n",
    "plt.scatter(concentration, absorbance, color='blue', label='Data')\n",
    "plt.plot(concentration, line, color='red', label='Calibration curve')\n",
    "for i in range(len(concentration)):\n",
    "    plt.plot([concentration[i], concentration[i]], [absorbance[i], line[i]], color='gray')\n",
    "plt.xlabel('Concentration (mg/L)')\n",
    "plt.ylabel('Absorbance value (530 nm)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92850d0",
   "metadata": {},
   "source": [
    "Isn't it great that we already have OLS functions to do this?\n",
    "\n",
    "## Confidence Intervals\n",
    "\n",
    "Fitting a calibration curve is not the end of the story. We need to know how confident we should be in the slope and intercept of the calibration curve, which is where confidence intervals come in. A confidence interval is a range of values likely to contain a parameter's true value. In the case of the calibration curve, we are interested in the confidence intervals for the slope and intercept of the line.\n",
    "\n",
    "### A Theoretical Interlude\n",
    "\n",
    "In OLS, the sum of squared errors (SSE) or residuals (SSR) is key in determining the confidence intervals for the slope and intercept. The SSR is defined as\n",
    "\n",
    "$$\n",
    "SSR = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "where $y_i$ is the observed value of the dependent variable, $\\hat{y}_i$ is the predicted value of the dependent variable, and $n$ is the number of data points. Looking at the plot above, this would correspond to summing the squares of the vertical distances (gray lines) between the observed data points and the line. The SSR is related to the variance of the residuals, which is defined as\n",
    "\n",
    "````{margin}\n",
    "```{note}\n",
    "We divide SSR by $n-2$ (not $n$) because estimating the slope and intercept uses up two degrees of freedom. This adjustment accounts for the parameters estimated, providing an unbiased estimate of the residual variance $\\sigma^2$.\n",
    "```\n",
    "````\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{SSR}{n-2}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of data points. The variance of the residuals is used to calculate the standard errors of the slope and intercept, which are then used to calculate the confidence intervals. The standard errors of the slope and intercept are defined as\n",
    "\n",
    "$$\n",
    "SE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\sigma^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "SE(\\hat{\\beta}_0) = \\sqrt{\\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\right)}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\beta}_1$ is the estimated slope, $\\hat{\\beta}_0$ is the estimated intercept, $x_i$ is the value of the independent variable, $\\bar{x}$ is the mean of the independent variable, and $n$ is the number of data points. The confidence intervals for the slope and intercept are then calculated as\n",
    "\n",
    "$$\n",
    "CI(\\hat{\\beta}_1) = \\hat{\\beta}_1 \\pm t_{\\alpha/2} SE(\\hat{\\beta}_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "CI(\\hat{\\beta}_0) = \\hat{\\beta}_0 \\pm t_{\\alpha/2} SE(\\hat{\\beta}_0)\n",
    "$$\n",
    "\n",
    "where $t_{\\alpha/2}$ is the critical value of the $t$-distribution with $n-2$ degrees of freedom and a significance level of $\\alpha/2$. The confidence intervals give us a range of values likely to contain the true value of the slope and intercept with a certain level of confidence.\n",
    "\n",
    "### Back to the Real World\n",
    "\n",
    "Let's calculate the confidence intervals for the calibration curve's slope and intercept. First, we will write our own functions. Then, we will use the `statsmodels` library to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff004326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals = absorbance - line\n",
    "\n",
    "# Calculate the sum of the squared residuals\n",
    "def sse(residuals):\n",
    "    return np.sum(residuals ** 2)\n",
    "\n",
    "# Test the function\n",
    "print(sse(residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc4f68",
   "metadata": {},
   "source": [
    "Now, let us write a function to compute the variance of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of the residuals\n",
    "def variance(residuals):\n",
    "    return sse(residuals) / (len(residuals) - 2)\n",
    "\n",
    "# Test the function\n",
    "print(variance(residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de82cf",
   "metadata": {},
   "source": [
    "OK, now we can calculate the standard errors of the slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard error of the slope\n",
    "def se_slope(x, residuals):\n",
    "    # numerator\n",
    "    numerator = variance(residuals)\n",
    "    # denominator\n",
    "    x_mean = np.mean(x)\n",
    "    denominator = np.sum((x - x_mean) ** 2)\n",
    "    return np.sqrt(numerator / denominator)\n",
    "\n",
    "# Test the function\n",
    "print(se_slope(concentration, residuals))\n",
    "\n",
    "# Calculate the standard error of the intercept\n",
    "def se_intercept(x, residuals):\n",
    "    # numerator\n",
    "    numerator = variance(residuals)\n",
    "    # denominator\n",
    "    x_mean = np.mean(x)\n",
    "    denominator = len(x) * np.sum((x - x_mean) ** 2)\n",
    "    return np.sqrt(numerator / denominator)\n",
    "\n",
    "# Test the function\n",
    "print(se_intercept(concentration, residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b566a5",
   "metadata": {},
   "source": [
    "Bringing it all together, we can calculate the confidence intervals for the slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confidence interval\n",
    "from scipy.stats import t\n",
    "\n",
    "def confidence_interval_slope(x, residuals, confidence_level):\n",
    "    # Calculate the standard error of the slope\n",
    "    se = se_slope(x, residuals)\n",
    "\n",
    "    # Calculate the critical t-value\n",
    "    n_data_points = len(x)\n",
    "    df = n_data_points - 2  # degrees of freedom\n",
    "    alpha = 1 - confidence_level\n",
    "    critical_t_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    return critical_t_value * se\n",
    "\n",
    "# Calculate the 95% confidence interval for the slope\n",
    "print(f\"slope: {slope:.3f} +/- {confidence_interval_slope(concentration, residuals, 0.95):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c9185",
   "metadata": {},
   "source": [
    "Now for the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confidence interval for the intercept\n",
    "def confidence_interval_intercept(x, residuals, confidence_level):\n",
    "    # Calculate the standard error of the intercept\n",
    "    se = se_intercept(x, residuals)\n",
    "\n",
    "    # Calculate the critical t-value\n",
    "    n_data_points = len(x)\n",
    "    df = n_data_points - 2  # degrees of freedom\n",
    "    alpha = 1 - confidence_level\n",
    "    critical_t_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    return critical_t_value * se\n",
    "\n",
    "# Calculate the 95% confidence interval for the intercept\n",
    "print(f\"intercept: {intercept:.3f} +/- {confidence_interval_intercept(concentration, residuals, 0.95):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5594b6",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "The last step in analyzing calibration data is to perform correlation analysis. Correlation analysis assesses the strength of the relationship between the two variables. In this case, we are interested in the correlation between the diacetyl concentration and the absorbance value. The correlation coefficient measures the strength and direction of the relationship between two variables. It ranges from -1 to 1, with 1 indicating a perfect positive relationship, -1 indicating a perfect negative relationship, and 0 indicating no relationship. The correlation coefficient is calculated as\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "where $x_i$ is the value of the independent variable, $\\bar{x}$ is the mean of the independent variable, $y_i$ is the value of the dependent variable, and $\\bar{y}$ is the mean of the dependent variable. The correlation coefficient gives us an indication of how well the two variables are related. A correlation coefficient close to 1 or -1 indicates a strong relationship, while a correlation coefficient close to 0 indicates a weak relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(10) * 10  # Independent variable\n",
    "y = 3 * x + np.random.randn(10) * 5  # Dependent variable\n",
    "\n",
    "# Calculate the mean of x and y\n",
    "mean_x = np.mean(x)\n",
    "mean_y = np.mean(y)\n",
    "\n",
    "# Calculate the deviations from the mean\n",
    "deviations_x = x - mean_x\n",
    "deviations_y = y - mean_y\n",
    "\n",
    "# Calculate the numerator and denominator of the correlation coefficient formula\n",
    "numerator = np.sum(deviations_x * deviations_y)\n",
    "denominator = np.sqrt(np.sum(deviations_x**2) * np.sum(deviations_y**2))\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation_coefficient = numerator / denominator\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, color='blue', label='Data points')\n",
    "\n",
    "# Plot the mean lines\n",
    "plt.axhline(mean_y, color='red', linestyle='--', label='Mean of y')\n",
    "plt.axvline(mean_x, color='green', linestyle='--', label='Mean of x')\n",
    "\n",
    "# Annotate deviations\n",
    "for i in range(len(x)):\n",
    "    plt.plot([x[i], x[i]], [mean_y, y[i]], color='gray', linestyle=':')\n",
    "    plt.plot([mean_x, x[i]], [y[i], y[i]], color='gray', linestyle=':')\n",
    "\n",
    "# Display the correlation coefficient on the plot\n",
    "plt.title('Correlation Analysis')\n",
    "plt.xlabel('Independent Variable (x)')\n",
    "plt.ylabel('Dependent Variable (y)')\n",
    "plt.legend()\n",
    "plt.text(1, 25, f'Correlation Coefficient: {correlation_coefficient:.2f}', fontsize=12, color='red')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3ec21",
   "metadata": {},
   "source": [
    "Let us calculate the correlation coefficient for the diacetyl concentration and the absorbance value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b33173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient\n",
    "def correlation_coefficient(x, y):\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    # Calculate the deviations from the mean\n",
    "    deviations_x = x - mean_x\n",
    "    deviations_y = y - mean_y\n",
    "\n",
    "    # Calculate the numerator and denominator of the correlation coefficient formula\n",
    "    numerator = np.sum(deviations_x * deviations_y)\n",
    "    denominator = np.sqrt(np.sum(deviations_x**2) * np.sum(deviations_y**2))\n",
    "\n",
    "    # Calculate the correlation coefficient\n",
    "    return numerator / denominator\n",
    "\n",
    "# Test the function\n",
    "print(correlation_coefficient(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c4db6",
   "metadata": {},
   "source": [
    "Applying this to our data, we get the following correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficient of the concentration and absorbance data\n",
    "print(correlation_coefficient(concentration, absorbance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50462af4",
   "metadata": {},
   "source": [
    "The correlation coefficient is close to 1, which indicates a strong positive relationship between the diacetyl concentration and the absorbance value. This means that the absorbance value can be used to predict the diacetyl concentration in beer with a high degree of accuracy, reinforcing the physical validity of the Beer-Lambert Law and the utility of the UV-Vis spectrometer for measuring diacetyl concentration accurately.\n",
    "\n",
    "```{admonition} A Familiar Form of the Correlation Coefficient\n",
    ":class: note\n",
    "Did you know that the $R^2$ value is the square of the correlation coefficient? $R^2$ value measures the proportion of the variance in the dependent variable that is predictable from the independent variable. In other words, it measures how well the independent variable predicts the dependent variable. The $R^2$ value ranges from 0 to 1, with 1 indicating a perfect fit and 0 indicating no fit.\n",
    "```\n",
    "\n",
    "## Hands-On Activity\n",
    "\n",
    "Now that you have learned how to analyze calibration data, it is time to test your skills. Here is a hands-on activity for you to try.\n",
    "\n",
    "An ideal diatomic gas has a temperature-independent constant pressure heat capacity of $C_V = 7R/2$, where $R$ is the gas constant. To assess deviations from this ideal behavior, a series of measurements of the heat capacity of a gas as a function of temperature were made. The data are as follows.\n",
    "\n",
    "| Temperature (K) | Heat Capacity (J/mol-K) |\n",
    "|-----------------|-------------------------|\n",
    "| 600             | 30.93                   |\n",
    "| 650             | 31.54                   |\n",
    "| 700             | 31.32                   |\n",
    "| 750             | 32.18                   |\n",
    "| 800             | 32.25                   |\n",
    "| 850             | 32.27                   |\n",
    "| 900             | 33.41                   |\n",
    "| 950             | 33.21                   |\n",
    "| 1000            | 33.97                   |\n",
    "\n",
    "1. Plot the data and fit a line to obtain the calibration curve.\n",
    "2. Calculate the confidence intervals for the slope and intercept of the calibration curve.\n",
    "3. Calculate the correlation coefficient between the temperature and heat capacity.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.4"
   }
  },
  "kernelspec": {
   "display_name": "comp-prob-solv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "source_map": [
   12,
   52,
   91,
   145,
   155,
   159,
   166,
   170,
   194,
   198,
   217,
   221,
   238,
   250,
   294,
   298,
   318,
   322,
   325
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}